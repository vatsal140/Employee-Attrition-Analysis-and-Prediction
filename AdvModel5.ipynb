{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a1ba7f-86c0-4f9b-a485-7bf869a558c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9159889419452124\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9165602747759067\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9206165703275531\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9206165703275531\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9229320599815699\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.1, max_depth=7, min_child_weight=7, n_estimators=100, n_jobs=1, subsample=0.9000000000000001, verbosity=0)\n",
      "TPOT Accuracy: 0.918918918918919\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       370\n",
      "           1       0.96      0.88      0.92       370\n",
      "\n",
      "    accuracy                           0.92       740\n",
      "   macro avg       0.92      0.92      0.92       740\n",
      "weighted avg       0.92      0.92      0.92       740\n",
      "\n",
      "Stacking Accuracy: 0.9297297297297298\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       370\n",
      "           1       0.96      0.90      0.93       370\n",
      "\n",
      "    accuracy                           0.93       740\n",
      "   macro avg       0.93      0.93      0.93       740\n",
      "weighted avg       0.93      0.93      0.93       740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "\n",
    "low_variance_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df = df.drop(columns=low_variance_cols)\n",
    "\n",
    "categorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "numeric_cols = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', \n",
    "                'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', \n",
    "                'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', \n",
    "                'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', \n",
    "                'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', \n",
    "                'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "X = df.drop(columns=['Attrition'])\n",
    "y = LabelEncoder().fit_transform(df['Attrition'])\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "X_pca = pca.fit_transform(X_balanced)\n",
    "X_meta = pd.DataFrame(X_pca, columns=[f\"PCA_{i}\" for i in range(X_pca.shape[1])])\n",
    "\n",
    "X_combined = pd.concat([pd.DataFrame(X_balanced), X_meta], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_balanced, test_size=0.3, random_state=42, stratify=y_balanced)\n",
    "\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=50,\n",
    "    verbosity=2,\n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tpot = tpot.predict(X_test)\n",
    "print(\"TPOT Accuracy:\", accuracy_score(y_test, y_pred_tpot))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tpot))\n",
    "\n",
    "# Save the best pipeline\n",
    "tpot.export('best_pipeline.py')\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=500, random_state=42)\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', random_state=42)),\n",
    "        ('lgbm', LGBMClassifier(random_state=42)),\n",
    "        ('mlp', mlp)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Accuracy:\", accuracy_score(y_test, y_pred_stacking))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_stacking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9bf92-e0bf-416b-9192-98a0afb4c71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
